# å¥³æœ‹å‹
# 1ã€aiå¾—çŸ¥é“ä»–æ˜¯ä½ çš„æœ‹å‹ langchainä¸­æç¤ºè¯æ¨¡å—æ¥é™å®š
#    æœ‹å‹çš„æ€§æ ¼å’Œç±»å‹ç”±ç”¨æˆ·é€‰æ‹©
# 2ã€aiè¿˜èƒ½èƒ½è®°ä½ç”¨æˆ·å’Œå®ƒèŠå¤©çš„è®°å½•
#    langchainçš„memoryè®°å¿†æ¨¡å—æ¥å®ç°
# 3ã€éœ€è¦ä½¿ç”¨langchainçš„chainé“¾ï¼Œé“¾æŠŠæç¤ºè¯+æ¨¡å‹+è®°å¿†è¿æ¥èµ·æ¥
# æ„å»ºæˆ‘ä»¬çš„æç¤ºè¯ï¼Œé€šè¿‡æç¤ºè¯æ¥ç»™å¤§æ¨¡å‹å®šä¹‰è§„åˆ™
import base64
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory # åœ¨å†…å­˜ä¸­ä¿å­˜å†å²è®°å¿†çš„æ¨¡å—
from langchain.chains import ConversationChain


st.title('æˆ‘çš„ç”µå­é—ºèœœâ¤ï¸â¤ï¸ğŸ’•ğŸ’•')
st.subheader("æ‰¾ç”µå­é—ºèœœï¼Œäº«èµ›åšäººç”Ÿ")
if "gms" not in st.session_state:
    st.session_state.gms =[]

for gm in st.session_state.gms:
    with st.chat_message(gm["role"]):
        st.write(gm["context"])


# æ„å»ºçš„å¤§æ¨¡å‹
llm = ChatOpenAI(
    model="glm-4-0520",
    api_key="4acbcfdec78dd13d0c037ecbb34560af.ZD9q6NLklwT0A1Bp",
    temperature=0.99,
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
# æ„å»ºè®°å¿†æ¨¡å—
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory()
# é€šè¿‡é“¾æŠŠä¸‰ä¸ªæ¨¡å—ç»™è¿æ¥èµ·æ¥
# ConversationChainé“¾ä¹‹æ‰€ä»¥èƒ½æ‰€ä»¥å†å²è®°å¿†å­˜å‚¨ï¼Œä¸»è¦æ˜¯å› ä¸ºä¼šåšä¸€ä»¶äº‹æƒ…ï¼Œä¼šæŠŠmemoryè®°å¿†æ¨¡å—ä¸­çš„æ•°æ®ä»¥historyå‚æ•°åçš„å½¢å¼
# å°è£…åˆ°é“¾çš„PromptTemplateæç¤ºè¯æ¨¡æ¿å½“ä¸­
temp = "ç°åœ¨ä½ è¦æ‰®æ¼”ä¸€ä¸ªé—ºèœœçš„è§’è‰²ï¼Œä½ çš„æ€§æ ¼æ˜¯"+st.session_state.xingge+"ï¼Œä½ åªéœ€è¦å›ç­”ä½ ç”¨æˆ·çš„è¯å³å¯ï¼Œä¸éœ€è¦é‡å¤ç”¨æˆ·çš„è¯ï¼Œä¹Ÿä¸éœ€è¦å°†ä½ çš„è§’è‰²å’Œæ€§æ ¼è¿›è¡Œå±•ç¤ºã€‚ä½ çš„ç”¨æˆ·è¯´çš„è¯æ˜¯:{input},ä½ ä»¬çš„ä»¥å‰çš„å¯¹è¯æ˜¯{history}"
prompt = PromptTemplate(
    input_variables=["input","history"],
    template=temp
)
chain = ConversationChain(
    prompt=prompt,
    llm=llm,
    memory=st.session_state.memory
)

input = st.chat_input("å’Œä½ çš„é—ºèœœè¯´ç‚¹è¯å§")
if input:
    with st.chat_message("user"):
        st.write(input)
    st.session_state.gms.append({"role":"user","context":input})
    # è°ƒç”¨å¤§æ¨¡å‹å›ç­”æˆ‘ä»¬çš„é—®é¢˜
    result = chain.invoke(input)
    # å¸¦æœ‰è®°å¿†çš„é“¾resultä¸­æ²¡æœ‰content,
    with st.chat_message("assistant"):
        st.write(result["response"])
    st.session_state.gms.append({"role":"assistant","context":result["response"]})

def main_bg(main_bg):
    main_bg_ext = "png"
    st.markdown(
        f"""
         <style>
         .stApp {{
             background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, "rb").read()).decode()});
             background-size: cover
         }}
         </style>
         """,
        unsafe_allow_html=True
    )
# è°ƒç”¨
main_bg('4.jpg')
